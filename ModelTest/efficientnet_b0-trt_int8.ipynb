{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d29af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT version: 8.4.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c 'import tensorrt; print(\"TensorRT version: {}\".format(tensorrt.__version__))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb12d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282c5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_DIR = '/ImageNet'\n",
    "BATCH_SIZE = 1\n",
    "LOADER_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe122981",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "TRT_MODEL_FILE = '../Flask/Models/efficientnet_b0-trt_int8.plan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a411b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "with open(TRT_MODEL_FILE, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78142a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_0', 'output_0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a1c263",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "input_0 output_0\n",
      "DataType.FLOAT (1, 3, 224, 224)\n",
      "DataType.FLOAT (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(engine.get_binding_index('input_0'), engine.get_binding_index('output_0'))\n",
    "print(engine.get_binding_name(0), engine.get_binding_name(1))\n",
    "print(engine.get_binding_dtype(0), engine.get_binding_shape(0))\n",
    "print(engine.get_binding_dtype(1), engine.get_binding_shape(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92e44e",
   "metadata": {},
   "source": [
    "## Inference pipeline\n",
    "\n",
    "Starting with a deserialized engine, TensorRT inference pipeline consists of the following steps:\n",
    "\n",
    "- Create an execution context and specify input shape (based on the image dimensions for inference).\n",
    "- Allocate CUDA device memory for input and output.\n",
    "- Allocate CUDA page-locked host memory to efficiently copy back the output.\n",
    "- Transfer the processed image data into input memory using asynchronous host-to-device CUDA copy.\n",
    "- Kickoff the TensorRT inference pipeline using the asynchronous execute API.\n",
    "- Transfer the segmentation output back into pagelocked host memory using device-to-host CUDA copy.\n",
    "- Synchronize the stream used for data transfers and inference execution to ensure all operations are completes.\n",
    "- Finally, write out the segmentation output to an image file for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3b0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = engine.get_binding_shape(0)\n",
    "input_dtype = engine.get_binding_dtype(0)\n",
    "\n",
    "output_shape = engine.get_binding_shape(1)\n",
    "output_dtype = engine.get_binding_dtype(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5805e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = trt.volume(engine.get_binding_shape(0))\n",
    "dtype = trt.nptype(engine.get_binding_dtype(0))    \n",
    "input_hmem = cuda.pagelocked_empty(size, dtype)\n",
    "input_dmem = cuda.mem_alloc(input_hmem.nbytes)\n",
    "\n",
    "size = trt.volume(engine.get_binding_shape(1))\n",
    "dtype = trt.nptype(engine.get_binding_dtype(1))    \n",
    "output_hmem = cuda.pagelocked_empty(size, dtype)\n",
    "output_dmem = cuda.mem_alloc(output_hmem.nbytes)\n",
    "\n",
    "bindings = [int(input_dmem), int(output_dmem)]\n",
    "\n",
    "\n",
    "context = engine.create_execution_context()\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5f4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(input_tensor, context, bindings, input_hmem, input_dmem, output_hmem, output_dmem, stream):\n",
    "    np.copyto(input_hmem, input_tensor)\n",
    "    cuda.memcpy_htod_async(input_dmem, input_hmem, stream)\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    cuda.memcpy_dtoh_async(output_hmem, output_dmem, stream)\n",
    "    stream.synchronize()\n",
    "    return output_hmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d86611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8482b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageNet(root=IMAGENET_DIR, transform=transform, split='val')\n",
    "loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34cc1f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50000/50000\n",
      "top-1:  0.0010\n",
      "top-5:  0.0051\n",
      "Batch Size: 1\n",
      "Total Time: 124.2600 (0.0025)\n",
      "Average Prediction Time: 0.0015\n"
     ]
    }
   ],
   "source": [
    "n_top1 = 0\n",
    "n_top5 = 0\n",
    "cnt = 0\n",
    "\n",
    "s = time.time()\n",
    "pred_tms = []\n",
    "for images, labels in loader:\n",
    "\n",
    "    ss = time.time()\n",
    "    output = infer(images.ravel(), \n",
    "                   context, \n",
    "                   bindings, \n",
    "                   input_hmem, input_dmem, \n",
    "                   output_hmem, output_dmem, \n",
    "                   stream)\n",
    "    output = output.reshape(output_shape)\n",
    "    pred_tms.append(time.time()-ss)\n",
    "\n",
    "    cnt += output.shape[0]\n",
    "\n",
    "    top1_id = output.argmax(1)\n",
    "    top5_id = output.argsort(1)[:, ::-1][:, :5]\n",
    "\n",
    "    n_top1 += np.equal(top1_id, labels).sum()\n",
    "    n_top5 += np.max(np.isin(top5_id, labels), 1).sum()\n",
    "\n",
    "    print(f\"\\rstep: {cnt}/{len(dataset)}\", end='')\n",
    "    \n",
    "total_tm = time.time() - s\n",
    "print()\n",
    "print(f\"top-1:  {n_top1/cnt:0.4f}\")\n",
    "print(f\"top-5:  {n_top5/cnt:0.4f}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Total Time: {total_tm:0.4f} ({total_tm/len(dataset):0.4f})\")\n",
    "print(f\"Average Prediction Time: {np.mean(pred_tms):0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
