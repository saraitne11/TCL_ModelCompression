{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d29af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT version: 8.4.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c 'import tensorrt; print(\"TensorRT version: {}\".format(tensorrt.__version__))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb12d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282c5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_DIR = '/ImageNet'\n",
    "BATCH_SIZE = 128\n",
    "LOADER_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe122981",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "TRT_MODEL_FILE = '../Flask/Models/resnet34-trt_best.plan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a411b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_engine(engine_file_path):\n",
    "    assert os.path.exists(engine_file_path)\n",
    "    print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfd5222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file ../Flask/Models/resnet34-trt_best.plan\n"
     ]
    }
   ],
   "source": [
    "engine = load_engine(TRT_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d78142a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_0', 'output_0']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24a1c263",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "input_0 output_0\n",
      "DataType.FLOAT (1, 3, 224, 224)\n",
      "DataType.FLOAT (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(engine.get_binding_index('input_0'), engine.get_binding_index('output_0'))\n",
    "print(engine.get_binding_name(0), engine.get_binding_name(1))\n",
    "print(engine.get_binding_dtype(0), engine.get_binding_shape(0))\n",
    "print(engine.get_binding_dtype(1), engine.get_binding_shape(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92e44e",
   "metadata": {},
   "source": [
    "## Inference pipeline\n",
    "\n",
    "Starting with a deserialized engine, TensorRT inference pipeline consists of the following steps:\n",
    "\n",
    "- Create an execution context and specify input shape (based on the image dimensions for inference).\n",
    "- Allocate CUDA device memory for input and output.\n",
    "- Allocate CUDA page-locked host memory to efficiently copy back the output.\n",
    "- Transfer the processed image data into input memory using asynchronous host-to-device CUDA copy.\n",
    "- Kickoff the TensorRT inference pipeline using the asynchronous execute API.\n",
    "- Transfer the segmentation output back into pagelocked host memory using device-to-host CUDA copy.\n",
    "- Synchronize the stream used for data transfers and inference execution to ensure all operations are completes.\n",
    "- Finally, write out the segmentation output to an image file for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab2e650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(engine, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d86611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8482b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageNet(root=IMAGENET_DIR, transform=transform, split='val')\n",
    "loader = data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=LOADER_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34cc1f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50000/50000\n",
      "top-1:  0.7331\n",
      "top-5:  0.9218\n",
      "Batch Size: 128\n",
      "Total Time: 79.2918 (0.0016)\n",
      "Average Prediction Time: 0.0528\n"
     ]
    }
   ],
   "source": [
    "n_top1 = 0\n",
    "n_top5 = 0\n",
    "cnt = 0\n",
    "\n",
    "s = time.time()\n",
    "pred_tms = []\n",
    "for images, labels in loader:\n",
    "\n",
    "    ss = time.time()\n",
    "    output = ort_sess.run([_output], {_input: images.numpy()})\n",
    "    output = output[0]\n",
    "    pred_tms.append(time.time()-ss)\n",
    "\n",
    "    cnt += output.shape[0]\n",
    "\n",
    "    top1_id = output.argmax(1)\n",
    "    top5_id = output.argsort(1)[:, ::-1][:, :5]\n",
    "\n",
    "    n_top1 += np.equal(top1_id, labels).sum()\n",
    "    n_top5 += np.max(np.isin(top5_id, labels), 1).sum()\n",
    "\n",
    "    print(f\"\\rstep: {cnt}/{len(dataset)}\", end='')\n",
    "    \n",
    "total_tm = time.time() - s\n",
    "print()\n",
    "print(f\"top-1:  {n_top1/cnt:0.4f}\")\n",
    "print(f\"top-5:  {n_top5/cnt:0.4f}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Total Time: {total_tm:0.4f} ({total_tm/len(dataset):0.4f})\")\n",
    "print(f\"Average Prediction Time: {np.mean(pred_tms):0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
